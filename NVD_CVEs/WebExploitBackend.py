import ijson.backends.yajl2 as ijson
import time
#from xml.sax.handler import ContentHandler
#from xml.sax import make_parser
import xml.etree.cElementTree as ET
import urllib2
import gzip
import StringIO
import sys
import pysolr
import md5
from birdy.twitter import StreamClient
from datetime import datetime
from multiprocessing import Pool

solr_url='http://192.168.10.136:8983/solr/'
NUM_ROWS=1000000
SIZE=400
log_solr = pysolr.Solr(solr_url+'ExploitLog', timeout=60)
solr = pysolr.Solr(solr_url+'ExploitDB', timeout=60)

mitre_urls=[]
nvd_urls=[]
mitre_years=[]
nvd_years=[]

for i in range(1999, datetime.now().year+1):
    mitre_urls.append('https://cve.mitre.org/data/downloads/allitems-cvrf-year-'+str(i)+'.xml')
    mitre_years.append(i)
    if(i>=2002):
        nvd_urls.append('https://static.nvd.nist.gov/feeds/json/cve/1.0/nvdcve-1.0-'+str(i)+'.json.gz')
        nvd_years.append(i)
"""
class ParseXML(ContentHandler):

    def __init__(self):
        self.json = {'cve':'','desc':'', 'upload':'','edited':''}
        self.all_cves=[]
        self.refs=[]
        self.refsjson={'url':'', 'refdesc':''}
        self.is_title=False
        self.is_desc = False
        self.is_published = False
        self.is_modified = False
        self.is_url = False
        self.is_description=False
        self.results = solr.search('*:*', **{"fl": "id, mitre_hash", 'rows': NUM_ROWS})
        self.solrdic = {}
        for i in self.results:
            self.solrdic[i['id']] = i['mitre_hash']
        self.solr_list=[]
        self.log_list=[{'type': 'info', 'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")}]
        self.current_size=0

    def startElement(self, name, attrs):
        if name == 'Title':
            self.is_title=True
            
        if (name=='Note' and attrs.get('Type')=='Description'):
            self.is_desc = True
        
        if (name=='Note' and attrs.get('Type')=='Other'):
            if(attrs.get('Title')=='Published'):
                self.is_published = True
            elif(attrs.get('Title')=='Modified'):
                self.is_modified = True

        if (name=='URL'):
            self.is_url=True
        
        if (name=='Description'):
            self.is_description=True

    def endElement(self, name):
        if(name=='Title'):
            self.is_title=False

        if(name=='Note'):
            self.is_desc=False
            self.is_published=False
            self.is_modified=False

        if(name=='URL'):
            self.is_url=False

        if(name=='Description'):
            self.is_description=False
        
        if(name=='Reference'):
            self.refs.append(self.refsjson)
            self.refsjson={'url':'', 'refdesc':''}

        if(name=='Vulnerability'):
            self.json['id']=int(self.json['cve'].split('-')[1]+self.json['cve'].split('-')[2])
            if(self.json['upload']==''):
                del self.json['upload']
            if(self.json['edited']==''):
                del self.json['edited']
            if(len(self.refs)>0):
                self.json['refs']=self.refs
            self.refs=[]
            self.json['mitre_hash']=unicode(md5.new(str(self.json)).hexdigest(), 'utf-8')
            if(str(self.json['id']) in self.solrdic):
                if(self.json['mitre_hash']!=self.solrdic[str(self.json['id'])]):
                    self.solr_list.append(self.json)
                    log={}
                    log['id'] = self.json['id']
                    log['type'] = 'updated'
                    if('upload' in self.json):
                        log['upload'] = self.json['upload']
                    if('edited' in self.json):
                        log['edited'] = self.json['edited']
                    self.log_list.append(log)
            else:
                self.solr_list.append(self.json)
                log={}
                log['id'] = self.json['id']
                log['type'] = 'added'
                if('upload' in self.json):
                    log['upload'] = self.json['upload']
                if('edited' in self.json):
                    log['edited'] = self.json['edited']
                self.log_list.append(log)

            if(len(self.solr_list)>=SIZE):
                solr.add(self.solr_list)
                log_solr.add(self.log_list)
                self.solr_list=[]
                self.log_list=[{'type': 'info', 'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")}]
            self.json = {'cve':'','desc':'', 'upload':'','edited':''}
                
            
    def characters(self, content):
        if self.is_title:
            self.json['cve']+=content
            print content
        
        if self.is_desc:
            self.json['desc']+=content

        if self.is_published:
            self.json['upload']+=content

        if self.is_modified:
            self.json['edited']+=content

        if self.is_url:
            self.refsjson['url']+=content
            
        if self.is_description:
            self.refsjson['refdesc']+=content
"""
"""
def parse_XML(mitre_year):
    print 'Parsira se XML'
    #download_mitre('https://cve.mitre.org/data/downloads/allitems-cvrf-year-'+str(mitre_year)+'.xml')
    grabber=ParseXML()
    saxparser = make_parser()
    saxparser.setContentHandler(grabber)
    saxparser.parse('mitre-cve-'+str(mitre_year)+'.xml')
    grabber.log_list.append({'id': 'info', 'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")})
    if(len(grabber.solr_list)>0):
        solr.add(grabber.solr_list)
        log_solr.add(grabber.log_list)
    print 'Gotovo parsiranje XML'
"""

def download_mitre(mitre_year):
    url='https://cve.mitre.org/data/downloads/allitems-cvrf-year-'+str(mitre_year)+'.xml'
    r=urllib2.urlopen(url)
    file_name='mitre-cve-'+url[56:60]+'.xml'
    with open(file_name, 'wb') as fd:
        fd.write(r.read())

def download_nvd(nvd_year):
    request = urllib2.Request('https://static.nvd.nist.gov/feeds/json/cve/1.0/nvdcve-1.0-'+str(nvd_year)+'.json.gz')
    request.add_header('Accept-encoding', 'gzip')
    opener = urllib2.build_opener()
    f = opener.open(request)
    compresseddata = f.read()
    compressedstream = StringIO.StringIO(compresseddata)
    gzipper = gzip.GzipFile(fileobj=compressedstream)
    data = gzipper.read()
    file_name='nvd-cve-'+str(nvd_year)+'.json'
    with open(file_name, 'wb') as fd:
        fd.write(data)
        
def parse_XML(mitre_year):
    print 'parsing XML'
    tree = ET.parse('mitre-cve-'+str(mitre_year)+'.xml')
    results = solr.search('*:*', **{"fl": "id, mitre_hash", 'rows': NUM_ROWS})
    solrdic = {}
    for i in results:
        solrdic[i['id']] = i['mitre_hash']
    solr_list=[]
    log_list=[{'type': 'info', 'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")}]
    for elem in tree.iter():
        if elem.tag=='{http://www.icasi.org/CVRF/schema/vuln/1.1}Vulnerability':
            dic = handle_vulnerabilities(elem)
            if(dic['id'] in solrdic):
                if(dic['mitre_hash']!=solrdic[dic['id']]):
                    solr_list.append(dic)
                    log={}
                    log['id'] = dic['id']
                    log['type'] = 'updated'
                    if('upload' in dic):
                        log['upload'] = dic['upload']
                    if('edited' in dic):
                        log['edited'] = dic['edited']
                    log_list.append(log)
            else:
                solr_list.append(dic)
                log={}
                log['id'] = dic['id']
                log['type'] = 'added'
                if('upload' in dic):
                    log['upload'] = dic['upload']
                if('edited' in dic):
                    log['edited'] = dic['edited']
                log_list.append(log)

            if(len(solr_list)>=SIZE):
                solr.add(solr_list)
                log_solr.add(log_list)
                solr_list=[]
                log_list=[]
                
    if len(solr_list)>0:
        solr.add(solr_list)
        log_solr.add(log_list)


def handle_vulnerabilities(elem):
    NAMESPACE='{http://www.icasi.org/CVRF/schema/vuln/1.1}'
    json={}
    refjson={}
    refs=[]
    for child in elem:
        if child.tag==NAMESPACE+'Title':
            json['cve']=child.text
            json['id']=str(child.text[4:8]+child.text[9:])
        if child.tag==NAMESPACE+'Notes':
            for note in child:
                if(note.attrib['Type']=='Description'):
                    json['desc']=note.text
                elif(note.attrib['Type']=='Other'):
                    if(note.attrib['Title']=='Published'):
                        json['upload']=note.text
                    elif(note.attrib['Title']=='Modified'):
                        json['edited']=note.text

        if child.tag==NAMESPACE+'References':
            for reference in child:
                for detail_reference in reference:
                    if detail_reference.tag==NAMESPACE+'URL':
                        refjson['url']=detail_reference.text

                    if detail_reference.tag==NAMESPACE+'Description':
                        refjson['refdesc']=detail_reference.text
                        refs.append(refjson)
                        refjson={}

    json['refs']=refs
    json['mitre_hash']=unicode(md5.new(str(json)).hexdigest(), 'utf-8')
    return json

def parse_JSON(nvd_year):
    print 'parsing JSON'
    dic={}
    json = ijson.parse(open('nvd-cve-'+str(nvd_year)+'.json'))
    if(nvd_year==2002):
        results = solr.search('id:(1999* OR 2000* OR 2001* OR 2002*)', **{'rows': NUM_ROWS})
    else:
        results = solr.search('id:'+str(nvd_year)+'*', **{'rows': NUM_ROWS})
    solrdic = {}
    for i in results:
        solrdic[i['id']] = i
    solr_list=[]
    log_list=[{'type': 'info', 'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")}]
    for prefix, event, value in json:
        if(prefix=='CVE_Items.item.cve.CVE_data_meta.ID' and event=='string'):
            dic['cve']=str(value)
            dic['id']=str(value[4:8]+value[9:])

        if(prefix=='CVE_Items.item.cve.affects.vendor.vendor_data.item.vendor_name' and event=='string'):
            vendor_name=str(value)
        
        if(prefix=='CVE_Items.item.cve.affects.vendor.vendor_data.item.product.product_data.item.product_name' and event=='string'):
            app_name=str(value)

        if(prefix=='CVE_Items.item.cve.affects.vendor.vendor_data.item.product.product_data.item.version.version_data.item.version_value' and event=='string'):
            if('software_names' not in dic):
                dic['software_names']=[]
                
            if(value=='-' or value=='*'):
                dic['software_names'].append(vendor_name+'_'+app_name)
            else:
                dic['software_names'].append(vendor_name+'_'+app_name+'_'+value)

        if(prefix=='CVE_Items.item.impact.baseMetricV3.cvssV3.baseScore' and event=='number'):
            dic['cvssv3_score']=value

        if(prefix=='CVE_Items.item.impact.baseMetricV2.cvssV2.baseScore' and event=='number'):
            dic['cvssv2_score']=value

        if(prefix=='CVE_Items.item.impact.baseMetricV2.severity' and event=='string'):
            dic['cvssv2_severity']=value

        if(prefix=='CVE_Items.item.impact.baseMetricV3.cvssV3.baseSeverity' and event=='string'):
            dic['cvssv3_severity']=value
            
        if(prefix=='CVE_Items.item' and event=='end_map' and 'software_names' in dic):
            dic['nvd_hash']=unicode(md5.new(str(dic)).hexdigest(), 'utf-8')
            if(dic['id'] in solrdic):
                if('nvd_hash' in solrdic[dic['id']]):
                    if(solrdic[dic['id']]['nvd_hash']!=dic['nvd_hash']):
                        log={}
                        shortcut=solrdic[dic['id']]
                        shortcut['software_names']=dic['software_names']
                        shortcut['cvssv2_score']=dic['cvssv2_score']
                        shortcut['cvssv2_severity']=dic['cvssv2_severity']
                        if('cvssv3_score' in dic):
                            shortcut['cvssv3_score']=dic['cvssv3_score']
                            shortcut['cvssv3_severity']=dic['cvssv3_severity']
                        shortcut['nvd_hash']=dic['nvd_hash']
                        solr_list.append(shortcut)
                        log['id'] = dic['id']
                        log['type'] = 'updated'
                        if('upload' in shortcut):
                            log['upload'] = shortcut['upload']
                        if('edited' in shortcut):
                            log['edited'] = shortcut['edited']
                        log_list.append(log)
                else:
                    log={}
                    shortcut=solrdic[dic['id']]
                    shortcut['software_names']=dic['software_names']
                    shortcut['cvssv2_score']=dic['cvssv2_score']
                    shortcut['cvssv2_severity']=dic['cvssv2_severity']
                    if('cvssv3_score' in dic):
                        shortcut['cvssv3_score']=dic['cvssv3_score']
                        shortcut['cvssv3_severity']=dic['cvssv3_severity']
                    shortcut['nvd_hash']=dic['nvd_hash']
                    solr_list.append(shortcut)
                    log['id'] = dic['id']
                    log['type'] = 'updated'
                    if('upload' in shortcut):
                        log['upload'] = shortcut['upload']
                    if('edited' in shortcut):
                        log['edited'] = shortcut['edited']
                    log_list.append(log)

            if(len(solr_list)>=SIZE):
                solr.add(solr_list)
                log_solr.add(log_list)
                solr_list=[]
                log_list=[]
            dic={}
    if(len(solr_list)>0):
        solr.add(solr_list)
        log_solr.add(log_list)

    print 'Gotovo parsiranje JSON-a'

def parse_all_years():
    p=Pool(5)
    p.map(download_mitre, mitre_years)
    p.map(download_nvd, nvd_years)

    for i in range(1999, 2018):
        print i
        parse_XML(i)
        if(i>=2002):
            parse_JSON(i)
    

def twitter_listener():
    SLEEP_TIME = 300
    JOB_TIME = 86400
    start_time = time.time() - SLEEP_TIME
    client = StreamClient("AkdTk4Mj7pNZPtaPLoGc6et0s", "KSdjmpf3a1nwYlAGA0Rlg4ONt7AGC5jtbVKtcaVroX7GFJqzj6", "757186452186861568-VPjNfZT2029doPbqQopvOtyB7iVBeOL", "ZqkxkIkdPgsq3E6M53djD91v9IKiHdUy6SuQ5jnobBAk2")
    response = client.stream.statuses.filter.get(follow=['757186452186861568', '821806287461740544'])
    for data in response.stream():
        if('delete' not in data):
            print data.text
            if(data.user.screen_name == 'CVEnew' or data.user.screen_name == 'ZxDilmo'):
                if(time.time() - start_time >= JOB_TIME):
                    parse_all_years()
                    start_time=time.time()
                elif (time.time() - start_time >= SLEEP_TIME):
                    download_mitre(datetime.now().year)
                    download_nvd(datetime.now().year)
                    parse_XML(datetime.now().year)
                    parse_JSON(datetime.now().year)
                    start_time = time.time()

def main():
    twitter_listener()


if __name__ == '__main__':
    download_mitre(2017)
    download_nvd(2017)
    parse_XML(2017)
    parse_JSON(2017)

#http://localhost:8983/solr/ExploitDB/update?stream.body=<delete><query>*:*</query></delete>&commit=true
